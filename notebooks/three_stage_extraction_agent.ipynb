{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Three-Stage Extraction Agent Architecture\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook implements a robust three-stage architecture for extracting structured information from PDFs:\n",
    "\n",
    "1. **Scanner Agent**: Identifies ALL potential items (gaps/variables/techniques/findings) with verbatim quotes\n",
    "2. **Extractor Agent**: Creates schema-compliant JSON for each identified item\n",
    "3. **Validator Agent**: Validates schema compliance and verbatim quote accuracy\n",
    "\n",
    "The system builds a validated array incrementally, retrying failed items with specific error feedback.\n",
    "\n",
    "## Architecture Benefits\n",
    "\n",
    "- ‚úÖ Incremental validation (item-by-item)\n",
    "- ‚úÖ Progressive building (accumulates valid items)\n",
    "- ‚úÖ Targeted error recovery (specific feedback per item)\n",
    "- ‚úÖ Reusable pattern (same for gaps, variables, techniques, findings)\n",
    "- ‚úÖ Robust to failures (doesn't lose all progress on one error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import logging\n",
    "\n",
    "# Third-party imports\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import fitz  # PyMuPDF\n",
    "from fuzzywuzzy import fuzz\n",
    "import jsonschema\n",
    "from jsonschema import validate\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"‚úÖ All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if API_KEY:\n",
    "    print(\"‚úÖ API Key loaded\")\n",
    "    genai.configure(api_key=API_KEY)\n",
    "else:\n",
    "    print(\"‚ùå API Key not found. Please set GOOGLE_API_KEY in .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration for gemini-2.5-flash-lite\n",
    "MODEL_CONFIG = {\n",
    "    \"model_name\": \"gemini-2.0-flash-exp\",\n",
    "    \"temperature\": 0.1,  # Low for factual extraction\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 40,\n",
    "    \"max_output_tokens\": 8192,\n",
    "}\n",
    "\n",
    "# Validation configuration\n",
    "VALIDATION_CONFIG = {\n",
    "    \"context_match_threshold\": 0.90,  # 90% similarity for quote validation\n",
    "    \"max_retries\": 3,  # Maximum retry attempts per item\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=MODEL_CONFIG[\"model_name\"],\n",
    "    generation_config={\n",
    "        \"temperature\": MODEL_CONFIG[\"temperature\"],\n",
    "        \"top_p\": MODEL_CONFIG[\"top_p\"],\n",
    "        \"top_k\": MODEL_CONFIG[\"top_k\"],\n",
    "        \"max_output_tokens\": MODEL_CONFIG[\"max_output_tokens\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Model configured: {MODEL_CONFIG['model_name']}\")\n",
    "print(f\"‚úÖ Validation threshold: {VALIDATION_CONFIG['context_match_threshold']*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Extract text from PDF using PyMuPDF.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to PDF file\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with full_text, page_texts, and metadata\n",
    "    \"\"\"\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        \n",
    "        page_texts = []\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            text = page.get_text()\n",
    "            page_texts.append(text)\n",
    "        \n",
    "        full_text = \"\\n\\n\".join(page_texts)\n",
    "        \n",
    "        metadata = {\n",
    "            \"title\": doc.metadata.get(\"title\", \"\"),\n",
    "            \"author\": doc.metadata.get(\"author\", \"\"),\n",
    "        }\n",
    "        \n",
    "        doc.close()\n",
    "        \n",
    "        return {\n",
    "            \"full_text\": full_text,\n",
    "            \"page_texts\": page_texts,\n",
    "            \"metadata\": metadata,\n",
    "            \"page_count\": len(page_texts),\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error extracting PDF: {e}\")\n",
    "        raise\n",
    "\n",
    "print(\"‚úÖ PDF extraction function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize text for comparison.\n",
    "    Handles unicode, whitespace, and common OCR issues.\n",
    "    \"\"\"\n",
    "    import unicodedata\n",
    "    \n",
    "    if not text:\n",
    "        return \"\"\n",
    "    \n",
    "    # Unicode normalization\n",
    "    text = unicodedata.normalize('NFKD', text)\n",
    "    \n",
    "    # Replace various dash types\n",
    "    text = text.replace('‚Äì', '-').replace('‚Äî', '-')\n",
    "    \n",
    "    # Replace curly quotes\n",
    "    text = text.replace('"', '\"').replace('"', '\"')\n",
    "    text = text.replace(''', \"'\").replace(''', \"'\")\n",
    "    \n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "print(\"‚úÖ Text normalization function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_quote_in_pdf(quote: str, pdf_text: str, threshold: float = 0.90) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Validate that a quote appears in the PDF text with sufficient similarity.\n",
    "    \n",
    "    Args:\n",
    "        quote: Quote to validate\n",
    "        pdf_text: Full PDF text\n",
    "        threshold: Similarity threshold (0-1)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with validation results\n",
    "    \"\"\"\n",
    "    if not quote.strip():\n",
    "        return {\"valid\": False, \"score\": 0.0, \"reason\": \"Empty quote\"}\n",
    "    \n",
    "    # Normalize texts\n",
    "    norm_quote = normalize_text(quote).lower()\n",
    "    norm_pdf = normalize_text(pdf_text).lower()\n",
    "    \n",
    "    # Method 1: Direct exact match\n",
    "    if norm_quote in norm_pdf:\n",
    "        return {\"valid\": True, \"score\": 1.0, \"method\": \"exact_match\"}\n",
    "    \n",
    "    # Method 2: Fuzzy matching with sliding window\n",
    "    window_size = len(quote) + 100\n",
    "    stride = window_size // 2\n",
    "    \n",
    "    best_score = 0.0\n",
    "    for i in range(0, max(1, len(pdf_text) - window_size + 1), stride):\n",
    "        window = pdf_text[i:i + window_size]\n",
    "        norm_window = normalize_text(window).lower()\n",
    "        \n",
    "        # Try multiple matching methods\n",
    "        scores = [\n",
    "            fuzz.ratio(norm_quote, norm_window),\n",
    "            fuzz.partial_ratio(norm_quote, norm_window),\n",
    "            fuzz.token_sort_ratio(norm_quote, norm_window),\n",
    "        ]\n",
    "        score = max(scores) / 100.0\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "    \n",
    "    is_valid = best_score >= threshold\n",
    "    \n",
    "    return {\n",
    "        \"valid\": is_valid,\n",
    "        \"score\": best_score,\n",
    "        \"method\": \"fuzzy_match\" if is_valid else \"no_match\"\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Quote validation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_response(response_text: str) -> Any:\n",
    "    \"\"\"\n",
    "    Parse JSON from model response, handling markdown code blocks.\n",
    "    \n",
    "    Args:\n",
    "        response_text: Raw response from model\n",
    "        \n",
    "    Returns:\n",
    "        Parsed JSON object\n",
    "    \"\"\"\n",
    "    # Try direct parsing first\n",
    "    try:\n",
    "        return json.loads(response_text)\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "    \n",
    "    # Try extracting from markdown code blocks\n",
    "    patterns = [\n",
    "        r'```json\\s*(.+?)\\s*```',\n",
    "        r'```\\s*(.+?)\\s*```',\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, response_text, re.DOTALL)\n",
    "        if match:\n",
    "            try:\n",
    "                return json.loads(match.group(1))\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    \n",
    "    # If all else fails, raise error\n",
    "    raise json.JSONDecodeError(\"Could not parse JSON from response\", response_text, 0)\n",
    "\n",
    "print(\"‚úÖ JSON parsing function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gap Taxonomy (Example - Adapt for Variables/Techniques/Findings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gap thematic categories for reference\n",
    "GAP_CATEGORIES = {\n",
    "    \"membrane_structure_function\": \"Membrane Structure-Function Relationships\",\n",
    "    \"liposome_rbc_interaction\": \"Liposome-RBC Interaction Mechanisms\",\n",
    "    \"membrane_interaction_fusion\": \"Membrane Interaction and Fusion Mechanisms\",\n",
    "    \"lipid_movement_distribution\": \"Lipid Movement and Distribution\",\n",
    "    \"therapeutic_applications\": \"Therapeutic Applications and Advanced Modalities\",\n",
    "    # ... add all categories from your schema\n",
    "}\n",
    "\n",
    "# Gap schema template (simplified - use your full schema)\n",
    "GAP_SCHEMA_TEMPLATE = {\n",
    "    \"gap_statement\": \"\",\n",
    "    \"context\": [],  # Array of verbatim quotes\n",
    "    \"thoughts\": [],  # Step-by-step reasoning\n",
    "    \"summary\": \"\",\n",
    "    \"thematicCategorization\": {\n",
    "        \"context\": [],\n",
    "        \"thoughts\": [],\n",
    "        \"summary\": \"\",\n",
    "        \"thematicCategoryId\": \"\",\n",
    "        \"evidence_strength\": \"\"\n",
    "    },\n",
    "    \"gap_type\": {\n",
    "        \"context\": [],\n",
    "        \"thoughts\": [],\n",
    "        \"summary\": \"\",\n",
    "        \"type\": \"\",\n",
    "        \"resolution_status\": \"\"\n",
    "    },\n",
    "    \"text_location\": \"\",\n",
    "    \"significance\": \"\"\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Gap taxonomy and schema template defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Scanner Agent\n",
    "\n",
    "**Purpose**: Scan PDF and identify ALL potential gaps/variables/techniques/findings\n",
    "\n",
    "**Output**: List of candidates, each with:\n",
    "- Brief description\n",
    "- Verbatim quotes from PDF\n",
    "- Reasoning why this is a gap\n",
    "- Location in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScannerAgent:\n",
    "    \"\"\"\n",
    "    Stage 1: Scans PDF and identifies all potential items.\n",
    "    \n",
    "    This agent takes a broad view of the paper and identifies ALL candidates\n",
    "    for extraction, providing verbatim quotes and reasoning for each.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, extraction_type: str = \"gaps\"):\n",
    "        \"\"\"\n",
    "        Initialize scanner agent.\n",
    "        \n",
    "        Args:\n",
    "            model: Gemini model instance\n",
    "            extraction_type: Type of items to scan for (gaps/variables/techniques/findings)\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.extraction_type = extraction_type\n",
    "        self.logger = logging.getLogger(f\"ScannerAgent.{extraction_type}\")\n",
    "    \n",
    "    def get_system_prompt(self) -> str:\n",
    "        \"\"\"Get system prompt for scanner agent based on extraction type.\"\"\"\n",
    "        \n",
    "        if self.extraction_type == \"gaps\":\n",
    "            return \"\"\"\n",
    "You are a research gap identification specialist for scientific literature on liposome-RBC interactions.\n",
    "\n",
    "Your task is to SCAN the entire paper and identify ALL research gaps, limitations, and future research directions.\n",
    "\n",
    "For each gap you identify, provide:\n",
    "1. A brief description of the gap\n",
    "2. The EXACT verbatim sentences from the paper that indicate this gap\n",
    "3. Your reasoning for why these sentences indicate a research gap\n",
    "4. The location (section and approximate page)\n",
    "\n",
    "Look for:\n",
    "- Explicit limitations (\"However, this study has limitations...\")\n",
    "- Future research directions (\"Further investigation is needed...\")\n",
    "- Unresolved questions (\"It remains unclear...\")\n",
    "- Methodological gaps (\"Lack of...\", \"Absence of...\")\n",
    "- Knowledge gaps (\"Not fully understood...\")\n",
    "\n",
    "Focus on sections: Introduction, Discussion, Conclusion, Future Work, Limitations\n",
    "\n",
    "Output format (JSON):\n",
    "{\n",
    "  \"candidates\": [\n",
    "    {\n",
    "      \"description\": \"Brief description of the gap\",\n",
    "      \"verbatim_quotes\": [\"Exact sentence 1 from paper\", \"Exact sentence 2 from paper\"],\n",
    "      \"reasoning\": \"Why these sentences indicate a research gap\",\n",
    "      \"location\": \"Discussion section, page 8\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "CRITICAL: Quotes must be EXACT verbatim sentences from the paper, not paraphrased.\n",
    "\"\"\"\n",
    "        \n",
    "        # Add similar prompts for variables, techniques, findings\n",
    "        elif self.extraction_type == \"variables\":\n",
    "            return \"\"\"[Similar prompt structure for variables]...\"\"\"\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown extraction type: {self.extraction_type}\")\n",
    "    \n",
    "    def scan(self, pdf_text: str, max_length: int = 15000) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Scan PDF text and identify all candidate items.\n",
    "        \n",
    "        Args:\n",
    "            pdf_text: Full text from PDF\n",
    "            max_length: Maximum text length to send to model\n",
    "            \n",
    "        Returns:\n",
    "            List of candidate items with verbatim quotes\n",
    "        \"\"\"\n",
    "        self.logger.info(f\"Scanning PDF for {self.extraction_type}...\")\n",
    "        \n",
    "        # Truncate if too long (or implement chunking strategy)\n",
    "        if len(pdf_text) > max_length:\n",
    "            self.logger.warning(f\"PDF text too long ({len(pdf_text)} chars), truncating to {max_length}\")\n",
    "            # Smart truncation: keep beginning and end, which often have key sections\n",
    "            pdf_text = pdf_text[:max_length//2] + \"\\n[... middle section truncated ...]\\n\" + pdf_text[-max_length//2:]\n",
    "        \n",
    "        # Build prompt\n",
    "        system_prompt = self.get_system_prompt()\n",
    "        user_prompt = f\"\"\"\n",
    "Analyze this scientific paper and identify ALL {self.extraction_type}.\n",
    "\n",
    "Paper text:\n",
    "{pdf_text}\n",
    "\n",
    "Provide your analysis in JSON format with ALL identified candidates.\n",
    "\"\"\"\n",
    "        \n",
    "        full_prompt = f\"{system_prompt}\\n\\n{user_prompt}\"\n",
    "        \n",
    "        try:\n",
    "            # Call model\n",
    "            response = self.model.generate_content(full_prompt)\n",
    "            \n",
    "            if not response or not response.text:\n",
    "                raise ValueError(\"Empty response from model\")\n",
    "            \n",
    "            # Parse response\n",
    "            result = parse_json_response(response.text)\n",
    "            \n",
    "            candidates = result.get(\"candidates\", [])\n",
    "            \n",
    "            self.logger.info(f\"Identified {len(candidates)} candidate {self.extraction_type}\")\n",
    "            \n",
    "            return candidates\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error during scanning: {e}\")\n",
    "            raise\n",
    "\n",
    "print(\"‚úÖ Scanner Agent defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Extractor Agent\n",
    "\n",
    "**Purpose**: Take ONE candidate item and create complete schema-compliant JSON\n",
    "\n",
    "**Input**: \n",
    "- Candidate item (from Scanner)\n",
    "- PDF text\n",
    "- Schema template\n",
    "\n",
    "**Output**: Complete schema-compliant JSON for that item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractorAgent:\n",
    "    \"\"\"\n",
    "    Stage 2: Creates schema-compliant JSON for a single candidate item.\n",
    "    \n",
    "    Takes a candidate from the Scanner and expands it into a complete,\n",
    "    schema-compliant JSON object with all required fields.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, extraction_type: str = \"gaps\"):\n",
    "        \"\"\"\n",
    "        Initialize extractor agent.\n",
    "        \n",
    "        Args:\n",
    "            model: Gemini model instance\n",
    "            extraction_type: Type of item to extract\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.extraction_type = extraction_type\n",
    "        self.logger = logging.getLogger(f\"ExtractorAgent.{extraction_type}\")\n",
    "    \n",
    "    def get_system_prompt(self) -> str:\n",
    "        \"\"\"Get system prompt for extractor agent.\"\"\"\n",
    "        \n",
    "        if self.extraction_type == \"gaps\":\n",
    "            return \"\"\"\n",
    "You are a data extraction specialist for research gap analysis.\n",
    "\n",
    "Your task is to take an identified research gap and create a COMPLETE, SCHEMA-COMPLIANT JSON object.\n",
    "\n",
    "You will be given:\n",
    "1. A candidate gap with verbatim quotes\n",
    "2. The full paper text for reference\n",
    "3. The JSON schema to follow\n",
    "\n",
    "You must create a complete JSON object that includes:\n",
    "\n",
    "1. **gap_statement**: Clear, concise statement of the gap\n",
    "\n",
    "2. **context**: Array of VERBATIM quotes from the paper that support this gap\n",
    "   - Use ONLY the quotes provided in the candidate\n",
    "   - Do NOT paraphrase or modify\n",
    "   - Each quote should be a complete sentence\n",
    "\n",
    "3. **thoughts**: Array of reasoning steps (3-5 steps)\n",
    "   - Step 1: What makes this a gap?\n",
    "   - Step 2: How does it relate to liposome-RBC interactions?\n",
    "   - Step 3: Why is it significant?\n",
    "   - etc.\n",
    "\n",
    "4. **summary**: Concise synthesis (2-3 sentences)\n",
    "\n",
    "5. **thematicCategorization**: Classification of the gap\n",
    "   - context: Quotes showing category relevance\n",
    "   - thoughts: Reasoning for category selection\n",
    "   - summary: Why this category fits\n",
    "   - thematicCategoryId: One of the allowed category IDs\n",
    "   - evidence_strength: Strong/Moderate/Weak\n",
    "\n",
    "6. **gap_type**: Classification of gap temporality\n",
    "   - context: Quotes showing gap type\n",
    "   - thoughts: Reasoning for type selection\n",
    "   - summary: Why this type\n",
    "   - type: One of [\"Historical gap - addressed in prior literature\", \"Current gap - addressed in this paper\", \"Future gap - identified for future research\", \"Persistent gap - partially addressed but remains unsolved\"]\n",
    "   - resolution_status: One of [\"Fully resolved\", \"Partially resolved\", \"Unresolved\", \"Not applicable\"]\n",
    "\n",
    "7. **text_location**: Where in the paper (e.g., \"Discussion section, page 8\")\n",
    "\n",
    "8. **significance**: High/Medium/Low\n",
    "\n",
    "CRITICAL RULES:\n",
    "- All context arrays MUST contain only verbatim quotes from the paper\n",
    "- Thoughts arrays MUST have step-by-step reasoning\n",
    "- Summaries MUST be concise syntheses\n",
    "- Follow the exact schema structure\n",
    "\n",
    "Output pure JSON with no additional text.\n",
    "\"\"\"\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown extraction type: {self.extraction_type}\")\n",
    "    \n",
    "    def extract(\n",
    "        self, \n",
    "        candidate: Dict[str, Any], \n",
    "        pdf_text: str,\n",
    "        schema_template: Dict[str, Any],\n",
    "        error_feedback: Optional[str] = None\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Extract schema-compliant JSON for a single candidate.\n",
    "        \n",
    "        Args:\n",
    "            candidate: Candidate item from Scanner\n",
    "            pdf_text: Full PDF text\n",
    "            schema_template: Schema structure to follow\n",
    "            error_feedback: Optional error feedback from previous attempt\n",
    "            \n",
    "        Returns:\n",
    "            Complete schema-compliant JSON object\n",
    "        \"\"\"\n",
    "        self.logger.info(f\"Extracting {self.extraction_type} item: {candidate.get('description', 'Unknown')[:50]}...\")\n",
    "        \n",
    "        # Build prompt\n",
    "        system_prompt = self.get_system_prompt()\n",
    "        \n",
    "        user_prompt = f\"\"\"\n",
    "Create a complete schema-compliant JSON object for this {self.extraction_type[:-1]}:\n",
    "\n",
    "CANDIDATE:\n",
    "{json.dumps(candidate, indent=2)}\n",
    "\n",
    "SCHEMA TEMPLATE:\n",
    "{json.dumps(schema_template, indent=2)}\n",
    "\n",
    "FULL PAPER TEXT (for reference):\n",
    "{pdf_text[:5000]}... [truncated]\n",
    "\"\"\"\n",
    "        \n",
    "        # Add error feedback if this is a retry\n",
    "        if error_feedback:\n",
    "            user_prompt += f\"\"\"\n",
    "\n",
    "‚ö†Ô∏è PREVIOUS ATTEMPT HAD ERRORS:\n",
    "{error_feedback}\n",
    "\n",
    "Please fix these errors in your new response.\n",
    "\"\"\"\n",
    "        \n",
    "        full_prompt = f\"{system_prompt}\\n\\n{user_prompt}\"\n",
    "        \n",
    "        try:\n",
    "            # Call model\n",
    "            response = self.model.generate_content(full_prompt)\n",
    "            \n",
    "            if not response or not response.text:\n",
    "                raise ValueError(\"Empty response from model\")\n",
    "            \n",
    "            # Parse response\n",
    "            extracted = parse_json_response(response.text)\n",
    "            \n",
    "            self.logger.info(\"Extraction complete\")\n",
    "            \n",
    "            return extracted\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error during extraction: {e}\")\n",
    "            raise\n",
    "\n",
    "print(\"‚úÖ Extractor Agent defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: Validator Agent\n",
    "\n",
    "**Purpose**: Validate extracted JSON for:\n",
    "1. Schema compliance\n",
    "2. Verbatim quote accuracy (all context quotes must appear in PDF)\n",
    "\n",
    "**Output**: \n",
    "- Validation result (valid/invalid)\n",
    "- List of specific errors if invalid\n",
    "- Instructions for fixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidatorAgent:\n",
    "    \"\"\"\n",
    "    Stage 3: Validates extracted JSON for schema compliance and quote accuracy.\n",
    "    \n",
    "    Performs two levels of validation:\n",
    "    1. Schema validation: Checks structure and required fields\n",
    "    2. Quote validation: Verifies all context quotes appear verbatim in PDF\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, extraction_type: str = \"gaps\"):\n",
    "        \"\"\"\n",
    "        Initialize validator agent.\n",
    "        \n",
    "        Args:\n",
    "            extraction_type: Type of item being validated\n",
    "        \"\"\"\n",
    "        self.extraction_type = extraction_type\n",
    "        self.logger = logging.getLogger(f\"ValidatorAgent.{extraction_type}\")\n",
    "    \n",
    "    def validate_schema(self, extracted: Dict[str, Any], schema: Dict[str, Any]) -> Tuple[bool, List[str]]:\n",
    "        \"\"\"\n",
    "        Validate that extracted JSON matches schema structure.\n",
    "        \n",
    "        Args:\n",
    "            extracted: Extracted JSON object\n",
    "            schema: Schema to validate against\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (is_valid, list_of_errors)\n",
    "        \"\"\"\n",
    "        errors = []\n",
    "        \n",
    "        # Check for required top-level fields\n",
    "        required_fields = [\n",
    "            \"gap_statement\", \"context\", \"thoughts\", \"summary\",\n",
    "            \"thematicCategorization\", \"gap_type\", \"text_location\", \"significance\"\n",
    "        ]\n",
    "        \n",
    "        for field in required_fields:\n",
    "            if field not in extracted:\n",
    "                errors.append(f\"Missing required field: {field}\")\n",
    "        \n",
    "        # Validate context is an array\n",
    "        if \"context\" in extracted:\n",
    "            if not isinstance(extracted[\"context\"], list):\n",
    "                errors.append(\"Field 'context' must be an array\")\n",
    "            elif len(extracted[\"context\"]) == 0:\n",
    "                errors.append(\"Field 'context' must contain at least one quote\")\n",
    "        \n",
    "        # Validate thoughts is an array\n",
    "        if \"thoughts\" in extracted:\n",
    "            if not isinstance(extracted[\"thoughts\"], list):\n",
    "                errors.append(\"Field 'thoughts' must be an array\")\n",
    "            elif len(extracted[\"thoughts\"]) < 3:\n",
    "                errors.append(\"Field 'thoughts' must contain at least 3 reasoning steps\")\n",
    "        \n",
    "        # Validate thematicCategorization structure\n",
    "        if \"thematicCategorization\" in extracted:\n",
    "            cat = extracted[\"thematicCategorization\"]\n",
    "            if not isinstance(cat, dict):\n",
    "                errors.append(\"Field 'thematicCategorization' must be an object\")\n",
    "            else:\n",
    "                required_cat_fields = [\"context\", \"thoughts\", \"summary\", \"thematicCategoryId\", \"evidence_strength\"]\n",
    "                for field in required_cat_fields:\n",
    "                    if field not in cat:\n",
    "                        errors.append(f\"Missing field in thematicCategorization: {field}\")\n",
    "        \n",
    "        # Validate gap_type structure\n",
    "        if \"gap_type\" in extracted:\n",
    "            gt = extracted[\"gap_type\"]\n",
    "            if not isinstance(gt, dict):\n",
    "                errors.append(\"Field 'gap_type' must be an object\")\n",
    "            else:\n",
    "                required_gt_fields = [\"context\", \"thoughts\", \"summary\", \"type\", \"resolution_status\"]\n",
    "                for field in required_gt_fields:\n",
    "                    if field not in gt:\n",
    "                        errors.append(f\"Missing field in gap_type: {field}\")\n",
    "        \n",
    "        # Validate enums\n",
    "        if \"significance\" in extracted:\n",
    "            if extracted[\"significance\"] not in [\"High\", \"Medium\", \"Low\"]:\n",
    "                errors.append(f\"Invalid significance value: {extracted['significance']}\")\n",
    "        \n",
    "        is_valid = len(errors) == 0\n",
    "        return is_valid, errors\n",
    "    \n",
    "    def validate_quotes(\n",
    "        self, \n",
    "        extracted: Dict[str, Any], \n",
    "        pdf_text: str,\n",
    "        threshold: float = 0.90\n",
    "    ) -> Tuple[bool, List[str]]:\n",
    "        \"\"\"\n",
    "        Validate that all context quotes appear verbatim in the PDF.\n",
    "        \n",
    "        Args:\n",
    "            extracted: Extracted JSON object\n",
    "            pdf_text: Full PDF text\n",
    "            threshold: Similarity threshold for fuzzy matching\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (is_valid, list_of_errors)\n",
    "        \"\"\"\n",
    "        errors = []\n",
    "        \n",
    "        # Collect all context arrays\n",
    "        context_arrays = []\n",
    "        \n",
    "        # Top-level context\n",
    "        if \"context\" in extracted and isinstance(extracted[\"context\"], list):\n",
    "            context_arrays.append((\"context\", extracted[\"context\"]))\n",
    "        \n",
    "        # thematicCategorization context\n",
    "        if \"thematicCategorization\" in extracted:\n",
    "            cat = extracted[\"thematicCategorization\"]\n",
    "            if \"context\" in cat and isinstance(cat[\"context\"], list):\n",
    "                context_arrays.append((\"thematicCategorization.context\", cat[\"context\"]))\n",
    "        \n",
    "        # gap_type context\n",
    "        if \"gap_type\" in extracted:\n",
    "            gt = extracted[\"gap_type\"]\n",
    "            if \"context\" in gt and isinstance(gt[\"context\"], list):\n",
    "                context_arrays.append((\"gap_type.context\", gt[\"context\"]))\n",
    "        \n",
    "        # Validate each quote\n",
    "        for field_name, quotes in context_arrays:\n",
    "            for i, quote in enumerate(quotes):\n",
    "                if not isinstance(quote, str):\n",
    "                    errors.append(f\"{field_name}[{i}]: Quote must be a string\")\n",
    "                    continue\n",
    "                \n",
    "                if not quote.strip():\n",
    "                    errors.append(f\"{field_name}[{i}]: Quote is empty\")\n",
    "                    continue\n",
    "                \n",
    "                # Validate quote appears in PDF\n",
    "                validation = validate_quote_in_pdf(quote, pdf_text, threshold)\n",
    "                \n",
    "                if not validation[\"valid\"]:\n",
    "                    errors.append(\n",
    "                        f\"{field_name}[{i}]: Quote not found in PDF (score: {validation['score']:.2f})\\n\"\n",
    "                        f\"Quote: {quote[:100]}...\"\n",
    "                    )\n",
    "        \n",
    "        is_valid = len(errors) == 0\n",
    "        return is_valid, errors\n",
    "    \n",
    "    def validate(\n",
    "        self,\n",
    "        extracted: Dict[str, Any],\n",
    "        pdf_text: str,\n",
    "        schema: Dict[str, Any],\n",
    "        threshold: float = 0.90\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Perform complete validation: schema + quotes.\n",
    "        \n",
    "        Args:\n",
    "            extracted: Extracted JSON object\n",
    "            pdf_text: Full PDF text\n",
    "            schema: Schema to validate against\n",
    "            threshold: Quote similarity threshold\n",
    "            \n",
    "        Returns:\n",
    "            Validation result dictionary\n",
    "        \"\"\"\n",
    "        self.logger.info(\"Validating extracted item...\")\n",
    "        \n",
    "        all_errors = []\n",
    "        \n",
    "        # Schema validation\n",
    "        schema_valid, schema_errors = self.validate_schema(extracted, schema)\n",
    "        if not schema_valid:\n",
    "            all_errors.extend([f\"[SCHEMA] {e}\" for e in schema_errors])\n",
    "        \n",
    "        # Quote validation\n",
    "        quotes_valid, quote_errors = self.validate_quotes(extracted, pdf_text, threshold)\n",
    "        if not quotes_valid:\n",
    "            all_errors.extend([f\"[QUOTE] {e}\" for e in quote_errors])\n",
    "        \n",
    "        is_valid = len(all_errors) == 0\n",
    "        \n",
    "        if is_valid:\n",
    "            self.logger.info(\"‚úÖ Validation passed\")\n",
    "        else:\n",
    "            self.logger.warning(f\"‚ùå Validation failed with {len(all_errors)} errors\")\n",
    "        \n",
    "        return {\n",
    "            \"valid\": is_valid,\n",
    "            \"errors\": all_errors,\n",
    "            \"error_count\": len(all_errors),\n",
    "            \"schema_valid\": schema_valid,\n",
    "            \"quotes_valid\": quotes_valid\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Validator Agent defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Extraction Pipeline\n",
    "\n",
    "This orchestrates all three stages:\n",
    "1. Scanner identifies candidates\n",
    "2. For each candidate:\n",
    "   - Extractor creates schema-compliant JSON\n",
    "   - Validator checks it\n",
    "   - If invalid, retry with error feedback\n",
    "   - If valid, add to array\n",
    "3. Return complete validated array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeStageExtractionPipeline:\n",
    "    \"\"\"\n",
    "    Complete three-stage extraction pipeline.\n",
    "    \n",
    "    Orchestrates Scanner ‚Üí Extractor ‚Üí Validator with retry logic\n",
    "    to build a validated array of extracted items.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, extraction_type: str = \"gaps\"):\n",
    "        \"\"\"\n",
    "        Initialize pipeline with all three agents.\n",
    "        \n",
    "        Args:\n",
    "            model: Gemini model instance\n",
    "            extraction_type: Type of extraction (gaps/variables/techniques/findings)\n",
    "        \"\"\"\n",
    "        self.extraction_type = extraction_type\n",
    "        self.logger = logging.getLogger(f\"Pipeline.{extraction_type}\")\n",
    "        \n",
    "        # Initialize agents\n",
    "        self.scanner = ScannerAgent(model, extraction_type)\n",
    "        self.extractor = ExtractorAgent(model, extraction_type)\n",
    "        self.validator = ValidatorAgent(extraction_type)\n",
    "        \n",
    "        self.logger.info(\"Pipeline initialized with 3 agents\")\n",
    "    \n",
    "    def process(\n",
    "        self,\n",
    "        pdf_text: str,\n",
    "        schema_template: Dict[str, Any],\n",
    "        max_retries: int = 3,\n",
    "        validation_threshold: float = 0.90\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Run complete extraction pipeline.\n",
    "        \n",
    "        Args:\n",
    "            pdf_text: Full PDF text\n",
    "            schema_template: Schema structure to follow\n",
    "            max_retries: Maximum retry attempts per item\n",
    "            validation_threshold: Quote similarity threshold\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with results and statistics\n",
    "        \"\"\"\n",
    "        self.logger.info(f\"Starting {self.extraction_type} extraction pipeline...\")\n",
    "        \n",
    "        # STAGE 1: Scan for candidates\n",
    "        self.logger.info(\"STAGE 1: Scanning for candidates...\")\n",
    "        candidates = self.scanner.scan(pdf_text)\n",
    "        self.logger.info(f\"Found {len(candidates)} candidates\")\n",
    "        \n",
    "        if len(candidates) == 0:\n",
    "            self.logger.warning(f\"No {self.extraction_type} found in paper\")\n",
    "            return {\n",
    "                \"items\": [],\n",
    "                \"statistics\": {\n",
    "                    \"candidates_found\": 0,\n",
    "                    \"items_extracted\": 0,\n",
    "                    \"items_failed\": 0,\n",
    "                    \"total_retries\": 0\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        # STAGE 2 & 3: Extract and validate each candidate\n",
    "        valid_items = []\n",
    "        failed_items = []\n",
    "        total_retries = 0\n",
    "        \n",
    "        for idx, candidate in enumerate(candidates, 1):\n",
    "            self.logger.info(f\"\\n{'='*60}\")\n",
    "            self.logger.info(f\"Processing candidate {idx}/{len(candidates)}\")\n",
    "            self.logger.info(f\"Description: {candidate.get('description', 'Unknown')[:100]}...\")\n",
    "            \n",
    "            extracted = None\n",
    "            error_feedback = None\n",
    "            \n",
    "            for attempt in range(max_retries):\n",
    "                self.logger.info(f\"  Attempt {attempt + 1}/{max_retries}\")\n",
    "                \n",
    "                try:\n",
    "                    # STAGE 2: Extract\n",
    "                    self.logger.info(\"  STAGE 2: Extracting...\")\n",
    "                    extracted = self.extractor.extract(\n",
    "                        candidate=candidate,\n",
    "                        pdf_text=pdf_text,\n",
    "                        schema_template=schema_template,\n",
    "                        error_feedback=error_feedback\n",
    "                    )\n",
    "                    \n",
    "                    # STAGE 3: Validate\n",
    "                    self.logger.info(\"  STAGE 3: Validating...\")\n",
    "                    validation = self.validator.validate(\n",
    "                        extracted=extracted,\n",
    "                        pdf_text=pdf_text,\n",
    "                        schema=schema_template,\n",
    "                        threshold=validation_threshold\n",
    "                    )\n",
    "                    \n",
    "                    if validation[\"valid\"]:\n",
    "                        # Success! Add to valid items\n",
    "                        self.logger.info(\"  ‚úÖ VALID - Adding to array\")\n",
    "                        valid_items.append(extracted)\n",
    "                        break\n",
    "                    else:\n",
    "                        # Validation failed\n",
    "                        self.logger.warning(f\"  ‚ùå INVALID - {validation['error_count']} errors\")\n",
    "                        \n",
    "                        # Show errors\n",
    "                        for error in validation[\"errors\"][:3]:  # Show first 3 errors\n",
    "                            self.logger.warning(f\"    - {error}\")\n",
    "                        \n",
    "                        if attempt < max_retries - 1:\n",
    "                            # Prepare error feedback for retry\n",
    "                            error_feedback = \"\\n\".join(validation[\"errors\"])\n",
    "                            total_retries += 1\n",
    "                            self.logger.info(\"  üîÑ Retrying with error feedback...\")\n",
    "                        else:\n",
    "                            # Max retries reached\n",
    "                            self.logger.error(\"  ‚ö†Ô∏è  Max retries reached - FAILED\")\n",
    "                            failed_items.append({\n",
    "                                \"candidate\": candidate,\n",
    "                                \"last_attempt\": extracted,\n",
    "                                \"errors\": validation[\"errors\"]\n",
    "                            })\n",
    "                \n",
    "                except Exception as e:\n",
    "                    self.logger.error(f\"  üí• Exception during processing: {e}\")\n",
    "                    if attempt < max_retries - 1:\n",
    "                        total_retries += 1\n",
    "                        self.logger.info(\"  üîÑ Retrying...\")\n",
    "                    else:\n",
    "                        self.logger.error(\"  ‚ö†Ô∏è  Max retries reached - FAILED\")\n",
    "                        failed_items.append({\n",
    "                            \"candidate\": candidate,\n",
    "                            \"error\": str(e)\n",
    "                        })\n",
    "        \n",
    "        # Summary\n",
    "        self.logger.info(f\"\\n{'='*60}\")\n",
    "        self.logger.info(\"PIPELINE COMPLETE\")\n",
    "        self.logger.info(f\"  Candidates found: {len(candidates)}\")\n",
    "        self.logger.info(f\"  Items extracted: {len(valid_items)}\")\n",
    "        self.logger.info(f\"  Items failed: {len(failed_items)}\")\n",
    "        self.logger.info(f\"  Total retries: {total_retries}\")\n",
    "        self.logger.info(f\"  Success rate: {len(valid_items)/len(candidates)*100:.1f}%\")\n",
    "        \n",
    "        return {\n",
    "            \"items\": valid_items,\n",
    "            \"failed_items\": failed_items,\n",
    "            \"statistics\": {\n",
    "                \"candidates_found\": len(candidates),\n",
    "                \"items_extracted\": len(valid_items),\n",
    "                \"items_failed\": len(failed_items),\n",
    "                \"total_retries\": total_retries,\n",
    "                \"success_rate\": len(valid_items) / len(candidates) if candidates else 0\n",
    "            }\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Complete Pipeline defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Pipeline\n",
    "\n",
    "Now let's test the complete three-stage pipeline on a sample PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure test\n",
    "TEST_PDF_PATH = \"path/to/your/test.pdf\"  # UPDATE THIS\n",
    "\n",
    "# Or use an example path\n",
    "# TEST_PDF_PATH = \"/path/to/sample_paper.pdf\"\n",
    "\n",
    "print(f\"Test PDF: {TEST_PDF_PATH}\")\n",
    "print(\"\\n‚ö†Ô∏è  Make sure to update TEST_PDF_PATH with your actual PDF file path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract PDF text\n",
    "print(\"Extracting PDF text...\")\n",
    "pdf_data = extract_text_from_pdf(TEST_PDF_PATH)\n",
    "\n",
    "print(f\"‚úÖ Extracted {pdf_data['page_count']} pages\")\n",
    "print(f\"‚úÖ Total characters: {len(pdf_data['full_text']):,}\")\n",
    "print(f\"\\nFirst 500 characters:\")\n",
    "print(pdf_data['full_text'][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pipeline\n",
    "print(\"Initializing three-stage extraction pipeline...\")\n",
    "pipeline = ThreeStageExtractionPipeline(model, extraction_type=\"gaps\")\n",
    "print(\"‚úÖ Pipeline ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run pipeline\n",
    "print(\"Running extraction pipeline...\")\n",
    "print(\"This may take several minutes depending on paper length...\\n\")\n",
    "\n",
    "result = pipeline.process(\n",
    "    pdf_text=pdf_data['full_text'],\n",
    "    schema_template=GAP_SCHEMA_TEMPLATE,\n",
    "    max_retries=3,\n",
    "    validation_threshold=0.90\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXTRACTION COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "print(\"\\nüìä STATISTICS:\")\n",
    "pprint(result['statistics'])\n",
    "\n",
    "print(f\"\\nüìù EXTRACTED {len(result['items'])} VALID ITEMS:\")\n",
    "for i, item in enumerate(result['items'], 1):\n",
    "    print(f\"\\n--- Item {i} ---\")\n",
    "    print(f\"Statement: {item.get('gap_statement', 'N/A')[:100]}...\")\n",
    "    print(f\"Category: {item.get('thematicCategorization', {}).get('thematicCategoryId', 'N/A')}\")\n",
    "    print(f\"Significance: {item.get('significance', 'N/A')}\")\n",
    "    print(f\"Context quotes: {len(item.get('context', []))}\")\n",
    "\n",
    "if result['failed_items']:\n",
    "    print(f\"\\n‚ö†Ô∏è  {len(result['failed_items'])} ITEMS FAILED:\")\n",
    "    for i, failed in enumerate(result['failed_items'], 1):\n",
    "        print(f\"\\n--- Failed Item {i} ---\")\n",
    "        print(f\"Description: {failed['candidate'].get('description', 'N/A')[:100]}...\")\n",
    "        if 'errors' in failed:\n",
    "            print(f\"Errors: {len(failed['errors'])}\")\n",
    "            print(f\"First error: {failed['errors'][0][:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "output_file = \"gaps_extraction_result.json\"\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(result, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Results saved to: {output_file}\")\n",
    "print(f\"\\nFile size: {os.path.getsize(output_file):,} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Individual Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed view of first item\n",
    "if result['items']:\n",
    "    print(\"DETAILED VIEW OF FIRST EXTRACTED ITEM:\")\n",
    "    print(\"=\"*60)\n",
    "    pprint(result['items'][0])\n",
    "else:\n",
    "    print(\"No items extracted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptation for Other Extraction Types\n",
    "\n",
    "To adapt this pipeline for **variables**, **techniques**, or **findings**:\n",
    "\n",
    "1. **Update the Scanner prompt** (in `ScannerAgent.get_system_prompt()`)\n",
    "   - Change what to look for (variables, techniques, findings)\n",
    "   - Change which sections to focus on\n",
    "   - Keep same output structure\n",
    "\n",
    "2. **Update the Extractor prompt** (in `ExtractorAgent.get_system_prompt()`)\n",
    "   - Change field descriptions\n",
    "   - Keep context‚Üíthoughts‚Üísummary pattern\n",
    "   - Use appropriate thematic categories\n",
    "\n",
    "3. **Update schema template**\n",
    "   - Use variable/technique/finding schema structure\n",
    "   - Keep validation logic the same\n",
    "\n",
    "4. **Update validator required fields**\n",
    "   - Adjust field names in `ValidatorAgent.validate_schema()`\n",
    "   - Keep quote validation logic unchanged\n",
    "\n",
    "**The core three-stage architecture remains the same!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. ‚úÖ **Test this gap extraction pipeline thoroughly**\n",
    "   - Try on 3-5 different papers\n",
    "   - Analyze validation errors\n",
    "   - Refine prompts based on results\n",
    "\n",
    "2. **Adapt for other extraction types**\n",
    "   - Copy this notebook\n",
    "   - Update prompts and schema for variables\n",
    "   - Test and refine\n",
    "   - Repeat for techniques and findings\n",
    "\n",
    "3. **Integrate into full pipeline**\n",
    "   - Run all four extraction types on same paper\n",
    "   - Combine outputs\n",
    "   - Add final assessment agent\n",
    "\n",
    "4. **Optimize and productionize**\n",
    "   - Migrate to Python scripts\n",
    "   - Add caching\n",
    "   - Improve error handling\n",
    "   - Create CLI interface"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
